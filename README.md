# ðŸ“„ Chat with Your Documents â€“ RAG App

**Retrieval-Augmented Generation (RAG)** powered app to chat with your own PDF, Word, or PowerPoint files using `Ollama`, `LangChain`, and `Streamlit`.

Ask questions about your uploaded documents, the system retrieves relevant chunks and responds using a locally running LLM (e.g., Mistral via Ollama).

---

## ðŸš€ Features

- ðŸ“ Upload `.pdf`, `.docx`, and `.pptx` files
- âœ‚ï¸ Smart chunking with `RecursiveCharacterTextSplitter`
- ðŸ§  Embedding via `OllamaEmbeddings` (Mistral)
- ðŸ—‚ï¸ Fast in-memory vector store (no disk I/O delay)
- ðŸ” Similarity search-based retrieval
- ðŸ¤– LLM response constrained to document content
- âš¡ Streamlit UI with live Q&A

---

## ðŸ§± Tech Stack

- **[Streamlit](https://streamlit.io/)** â€“ Frontend interface
- **[LangChain](https://www.langchain.com/)** â€“ RAG pipeline components
- **[Ollama](https://ollama.com/)** â€“ Local language model inference
- **Mistral** â€“ LLM used for generation
- **Python 3.10+**

---

## ðŸ› ï¸ Installation

### Prerequisites

- Python 3.10+
- [Ollama](https://ollama.com/) installed on your system

### Step 1: Install Python Dependencies

```bash
pip install -r requirements.txt
```

### Step 2: Install and Setup Ollama

1. **Download and install Ollama** from [https://ollama.com/](https://ollama.com/)

2. **Pull the Mistral model**:

   ```bash
   ollama pull mistral
   ```

3. **Start Ollama service** (keep this running in a separate terminal):
   ```bash
   ollama serve
   ```

### Step 3: Run the Application

```bash
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

---

## ðŸŽ¯ Usage

1. **Upload Documents**: Drop your PDF, Word, or PowerPoint files
2. **Wait for Processing**: The app will chunk and embed your documents
3. **Ask Questions**: Type questions about your uploaded content
4. **Get Answers**: The AI will respond based only on your document content

---

## ðŸ“ Requirements

The project uses these key packages:

- `streamlit>=1.28.0` - Web interface
- `langchain-community>=0.0.1` - Document loaders
- `langchain-text-splitters>=0.0.1` - Text chunking
- `langchain-ollama>=0.1.0` - Ollama integration
- `langchain-core>=0.1.0` - Core LangChain components
